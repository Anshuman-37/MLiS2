{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "regularisation.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anshuman-37/MLiS2/blob/master/workshops/workshop2/regularisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9lgu7n44eFs"
      },
      "source": [
        "**Regularisation**\n",
        "\n",
        "In this example you are given a dataset (MNIST) with a limited number of training examples (only 1000 compared to the usual 60,000). \n",
        "\n",
        "Your goal is to implement regularisation methods to achive the **lowest possible test loss using this dataset**. \n",
        "\n",
        "You should consider methods given in the lectures including:\n",
        "\n",
        "*   Data augmentation - ? \n",
        "*   Early stopping - \n",
        "*   L1/L2 penalty norms -\n",
        "*   Dropout - Done\n",
        "\n",
        "You are free to change the network architecture and model complexity, but the main purpose of the workshop is to investigate regularisation (next week you will look at CNN architectures in detail). \n",
        "\n",
        "You are also free to change the choice of optimiser, and other hyper-parameters such as the batch size.  - Done\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNviuTwum6vs"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARZRYjHQnE-0"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I-MxTxAnH2d"
      },
      "source": [
        "tf.random.set_seed(1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxO576eJnMXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb6b4255-eca7-4d47-8246-8ec52bcdadbf"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4F_HTQpnvSk"
      },
      "source": [
        "First load the MNIST dataset and add a channels dimension (channels last convention)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twdc-t9FnN_9"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train[..., tf.newaxis].astype(np.float32)\n",
        "x_test = x_test[..., tf.newaxis].astype(np.float32)\n",
        "\n",
        "img_rows = x_train.shape[1]\n",
        "img_cols = x_train.shape[2]"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEsWYkNz5Po7"
      },
      "source": [
        "Let's use a much smaller training dataset of 1000 examples so overfitting is more problematic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qzt-HoIo4yks",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "193830ab-50ef-4127-daef-dca3b309db24"
      },
      "source": [
        "n_train = 1000\n",
        "x_train = x_train[0:n_train, :]\n",
        "y_train = y_train[0:n_train]\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2JSWYGKjsPh"
      },
      "source": [
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(15, 15))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(np.squeeze(img))\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDfQh4AfoBAH"
      },
      "source": [
        "Let's visualise several training examples - to do this we use the keras ImageDataGenerator. We rescale images by 1/255 to normalise them in the range (0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuOz9BopjZPq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "0bfc96f5-9055-4008-8fdb-2e6b60d322da"
      },
      "source": [
        "# image_generator = ImageDataGenerator(rescale=1./255) \n",
        "# data_gen = image_generator.flow(x_train, y_train, batch_size=32) \n",
        "# sample_images, sample_labels = next(data_gen)\n",
        "# plotImages(sample_images[:5])\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-35-7a2171b11730>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    plotImages(sample_images[:5]\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Refer this for why we should rescale the images \n",
        "# https://github.com/Arsey/keras-transfer-learning-for-oxford102/issues/1\n",
        "image_generator = ImageDataGenerator(rescale=1./255) \n",
        "data_gen = image_generator.flow(x_train, y_train, batch_size=32) \n",
        "sample_images, sample_labels = next(data_gen)\n",
        "plotImages(sample_images[:5])"
      ],
      "metadata": {
        "id": "ORY3aQeLH2yM",
        "outputId": "e0b049c3-7d26-47e5-9fb5-1762a7d0101b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 5 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8bStvJVoVlj"
      },
      "source": [
        "One regularisation method to deal with over-fitting is data augmentation. The image generator can apply various transformations to data - here we apply a random rotation of upto 20 degrees and visualise the same training example with different augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz28zlncmIiP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "e39ad620-c402-42f1-97e5-4e563baa130d"
      },
      "source": [
        "image_generator = ImageDataGenerator(rescale=1./255,rotation_range=20) \n",
        "data_gen = image_generator.flow(x_train, y_train, batch_size=32) \n",
        "augmented_images = [data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 5 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIE6-wlA3J4h"
      },
      "source": [
        "Define a basic CNN with 32 convolutional filters using a 3x3 kernel, followed by a dense fully connected layer of 128 units and an output layer of 10 units with softmax activation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKolHZQUL8-4"
      },
      "source": [
        "class BasicCNN(Model):\n",
        "    def __init__(self):\n",
        "        super(BasicCNN, self).__init__()\n",
        "        self.conv1 = Conv2D(128, 3, activation='relu')\n",
        "        self.polling1 =MaxPooling2D((2, 2), strides=(2, 2))\n",
        "        self.conv2 = Conv2D(64, 3, activation='relu')\n",
        "        self.polling2 =MaxPooling2D((2, 2), strides=(2, 2))\n",
        "        self.flatten = Flatten()\n",
        "        self.d1 = Dense(128, activation='elu')\n",
        "        self.drp_out = Dropout(0.25)#input_shape=(128,))\n",
        "        self.d2 = Dense(64, activation='elu')\n",
        "        self.d3 = Dense(10, activation='softmax')\n",
        "    \n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.polling1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.polling2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.d1(x)\n",
        "        x = self.drp_out(x)\n",
        "        x = self.d2(x)\n",
        "        return self.d3(x)\n"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuhNDi134B2G"
      },
      "source": [
        "Main training routine - uses the more detailed Gradient Tape API to iterate over the dataset and update the weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZH8jdqKohiU"
      },
      "source": [
        " def trainer(cls, train_image_generator, test_image_generator, \n",
        "            verbose=False, batch_size=32, max_epochs=5):\n",
        "     #New varaiables to append train and test loss\n",
        "  tr_loss = []\n",
        "  te_loss = []\n",
        "  model = cls()\n",
        "\n",
        "  train_data_gen = train_image_generator.flow(x_train, y_train, \n",
        "                                              batch_size=batch_size) \n",
        "\n",
        "  test_data_gen = test_image_generator.flow(x_test, y_test, \n",
        "                                              batch_size=batch_size) \n",
        "\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "  train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='train_accuracy')\n",
        "  tr_loss.append(train_loss)\n",
        "  test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "  test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='test_accuracy')\n",
        "  te_loss.append(te_loss)\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = model(images, training=True)\n",
        "      loss = loss_object(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    train_loss(float(loss))\n",
        "    train_accuracy(labels, predictions)\n",
        "\n",
        "  @tf.function\n",
        "  def test_step(images, labels):\n",
        "    predictions = model(images, training=False)\n",
        "    t_loss = loss_object(labels, predictions)\n",
        "    test_loss(float(t_loss))\n",
        "    test_accuracy(labels, predictions)\n",
        "\n",
        "  for epoch in range(max_epochs):\n",
        "    # Reset the metrics at the start of the next epoch\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()\n",
        "\n",
        "    batches = 0\n",
        "    for images, labels in train_data_gen:\n",
        "      train_step(images, labels)\n",
        "      batches += 1\n",
        "      if batches >= len(x_train) / batch_size:\n",
        "        break\n",
        "\n",
        "    batches = 0\n",
        "    for images, labels in test_data_gen:\n",
        "      test_step(images, labels)\n",
        "      batches += 1\n",
        "      if batches >= len(x_test) / batch_size:\n",
        "        break\n",
        "\n",
        "    if verbose:\n",
        "      template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "      print(template.format(epoch+1,\n",
        "                            train_loss.result(),\n",
        "                            train_accuracy.result()*100,\n",
        "                            test_loss.result(),\n",
        "                            test_accuracy.result()*100))\n",
        "  \n",
        "  return test_loss.result().numpy(), tr_loss, te_loss"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBSBEZftgDsL"
      },
      "source": [
        "Baseline run with no regularisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkemC6SvTLOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08acd512-ccd2-4d9e-f743-e8c0c658a4a4"
      },
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=None) \n",
        "test_image_generator = ImageDataGenerator(rescale=None)\n",
        "epochs = 10\n",
        "final_test_loss ,train_Loss , test_loss = trainer(BasicCNN, train_image_generator, test_image_generator, verbose=True, max_epochs=epochs)\n",
        "print('Final test loss:', final_test_loss)\n",
        "epochs = np.arange(1,9)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.8537087440490723, Accuracy: 43.39999771118164, Test Loss: 0.8362647294998169, Test Accuracy: 73.52999877929688\n",
            "Epoch 2, Loss: 0.6166244149208069, Accuracy: 80.5, Test Loss: 0.4585306644439697, Test Accuracy: 85.48999786376953\n",
            "Epoch 3, Loss: 0.3555760085582733, Accuracy: 88.80000305175781, Test Loss: 0.3446219265460968, Test Accuracy: 89.45000457763672\n",
            "Epoch 4, Loss: 0.18791617453098297, Accuracy: 93.9000015258789, Test Loss: 0.321355938911438, Test Accuracy: 90.58999633789062\n",
            "Epoch 5, Loss: 0.1064964309334755, Accuracy: 96.10000610351562, Test Loss: 0.2796262800693512, Test Accuracy: 92.19999694824219\n",
            "Epoch 6, Loss: 0.11959874629974365, Accuracy: 96.0, Test Loss: 0.3376271426677704, Test Accuracy: 90.83999633789062\n",
            "Epoch 7, Loss: 0.07466882467269897, Accuracy: 97.79999542236328, Test Loss: 0.3456416130065918, Test Accuracy: 91.13999938964844\n",
            "Epoch 8, Loss: 0.06734921783208847, Accuracy: 97.5999984741211, Test Loss: 0.2931242287158966, Test Accuracy: 92.66999816894531\n",
            "Epoch 9, Loss: 0.06640595197677612, Accuracy: 98.0999984741211, Test Loss: 0.2957320213317871, Test Accuracy: 92.3699951171875\n",
            "Epoch 10, Loss: 0.05900638923048973, Accuracy: 97.5, Test Loss: 0.236538365483284, Test Accuracy: 93.77999877929688\n",
            "Final test loss: 0.23653837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx1vid62esyU"
      },
      "source": [
        ""
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MUQ2Ax9h0P2F"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RdslNfrL0WG5"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sEPbmK2a0ZPD",
        "outputId": "41560dfd-1fe4-4f15-9c9e-afab3e5f011b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7105555555555555"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pq4cBHuT0i-e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}